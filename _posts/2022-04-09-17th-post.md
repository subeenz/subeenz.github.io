## ANN(Artificial Neural Network)

* 사람의 신경망 원리와 구조를 모방하여 만든 기계학습 알고리즘

  > 인간의 뇌에서 뉴런들이 어떤 신호, 자극 등을 받고, 그 자극이 어떠한 임계값(threshold)을 넘어서면 결과 신호를 전달하는 과정에서 착안한 것

* 가중치를 적용한 방향성 그래프

* 구성

  > 신경망은 다수의 입력 데이터를 받는 **입력층(Input Layer),** 
  >
  > 데이터의 출력을 담당하는 **출력층(Output Layer)**, 
  >
  > 입력층과 출력층 사이에 존재하는 레이어인 **은닉층(Hidden Layer)**이 존재
  >
  > > 은닉층에서는 활성화함수(Active Function)를 사용하여 최적의 가중치(Weight)와 편향(Bias)을 찾아내는 역할을 합니다.

  은닉층과 노드의 개수를 구성 (= 모델을 구성한다)

  따라서 모델을 잘 구성하여 원하는 output값을 잘 예측하는 것이 목표

  

### Perceptron

* 퍼셉트론(Perceptron)은 가장 **단순**한 유형의 인공 신경망

* 단층 퍼셉트론은 입력층, 출력층 두 단계로 이루어짐

* 층이 하나인 TLU(threshold logic unit)로 구성. 각 TLU는 모든 input(입력)에 연결

  > TLU = Perceptron

* input의 합(=weighted summation)이 Threshold 이상이면 1을 출력, 그렇지 않으면 0을 출력하는 유닛

  > 데이터를 선형적으로 분리할 수 있는 경우에만 효과가 있다. 
  >
  > -> 주로 이진법에 쓰임

  ![퍼셉트론3.PNG (313×280)](https://wikidocs.net/images/page/24958/%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A03.PNG)

### Multilayer Perceptron, MLP

* 다층 신경망, 다층 퍼셉트론

  > 주로 복잡한 분류나 회귀 작업을 해결하는 데 사용
  >
  > 단일 layer를 갖는 신경망 모델은 threshold를 1개밖에 가질 수 없으므로, XOR를 만들 수가 없는 문제를 해결

### 문제점

- 학습과정에서 파라미터의 최적값을 찾기 어려움

  > 출력값을 결정하는 활성화함수의 사용은 기울기 값에 의해 weight가 결정되었는데 이런 gradient값이 뒤로 갈수록 점점 작아져 0에 수렴하는 오류를 낳기도 하고 부분적인 에러를 최저 에러로 인식하여 더이상 학습을 하지 않는 경우도 있습니다.

- Overfitting에 따른 문제

- 학습시간이 느림

  > 은닉층이 많으면 학습하는데에 정확도가 올라가지만 그만큼 연산량이 기하 급수적으로 늘어나게 됨
  >
  > 그래픽카드의 발전으로 어느정도 해결, 오버피팅문제는 사전훈련(pre-train)을 통해 방지

## DNN (Deep Neural Network)

* ANN 기법의 여러문제가 해결되면서 모델 내 은닉층을 많이 늘려서 학습의 결과를 향상 시키는 방법
* 응용 알고리즘 : CNN, RNN, LSTM, GRU 등



## 분석망 비교

![R1280x0 (1280×640)](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcEZJBF%2FbtqNpGOj3Ob%2Fzj6suBvXW1kK0IKy5SoEwk%2Fimg.png)

## References

* https://ebbnflow.tistory.com/119
* https://dbrang.tistory.com/1537